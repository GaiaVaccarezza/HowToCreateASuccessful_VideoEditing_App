{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLORATORY ANALYSIS"
      ],
      "metadata": {
        "id": "24ltSdJOPmWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcsJyJj8kmIu"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQM-QSe0rDYd"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANALYSIS OF THE DATASET"
      ],
      "metadata": {
        "id": "poMgJDNI9mWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y6EWhR6lWlk"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "df = pd.read_csv('reviews_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "l3405-8qIzoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBLYqoxFlvDA"
      },
      "outputs": [],
      "source": [
        "# view columns\n",
        "df.columns\n",
        "# first column should be index, we\n",
        "df.set_index('Unnamed: 0', inplace = True)\n",
        "# set index names as ID\n",
        "df.index.name = 'ID'\n",
        "# rename columns to make them pythonic (i.e. replace spaces with underscore)\n",
        "# this allows to access them with df.name easily\n",
        "new_column_naming = {}\n",
        "for col in df.columns:\n",
        "  new_col = col.replace(' ', '_').lower()\n",
        "\n",
        "  new_column_naming[col] = new_col\n",
        "df.rename(new_column_naming, axis = 1, inplace = True)\n",
        "# additionally, rename the 'at' column since 'at' is a method in pandas\n",
        "df.rename({'at':'time'}, axis = 1, inplace = True)\n",
        "# lastly, rename the column 'retouch (face/body)' to make it machine readable\n",
        "df.rename({'retouch_(face/body)' : 'retouch_face_or_body'}, axis = 1, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A4Ur4-4mDX2"
      },
      "outputs": [],
      "source": [
        "# basic description of dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrq0AmTsmyX3"
      },
      "outputs": [],
      "source": [
        "# basic description of dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2REZPBiypaxO"
      },
      "outputs": [],
      "source": [
        "# preliminary unsatisfactory identification of numerical and categorical_variables\n",
        "numerical_columns = df._get_numeric_data().columns.tolist()\n",
        "categorical_columns = list(set(df.columns) - set(numerical_columns))\n",
        "print('found {} categorical variables'.format(len(df.columns) - len(numerical_columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulbaecWGsLVz"
      },
      "outputs": [],
      "source": [
        "# first of all we convert the 'time' column into a datetime format\n",
        "df.time = pd.to_datetime(df['time'])\n",
        "timestamp_columns = ['time']\n",
        "categorical_columns.remove('time')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydOiEIb4ujZo"
      },
      "outputs": [],
      "source": [
        "numerical_columns, categorical_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDIZxkEKD3Eb"
      },
      "source": [
        "## PRELIMINARY GRAPHICAL DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjRWIcdQD6WW"
      },
      "outputs": [],
      "source": [
        "# in this subsection, we aim to explore the dataset to see potential clues in the data\n",
        "# without assuming a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58hVhD3NFW1y"
      },
      "outputs": [],
      "source": [
        "# create a local directory for images\n",
        "! mkdir imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQ4c0YvEQ5V"
      },
      "outputs": [],
      "source": [
        "# we should just keep score_x of this\n",
        "df[categorical_columns].hist(figsize = (20, 20))\n",
        "plt.title('Categorical Columns Reviews Dataframe')\n",
        "plt.savefig('imgs/histogram_categorical_cols.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_OHffve1Iat"
      },
      "outputs": [],
      "source": [
        "ax = df.score_x.hist()\n",
        "ax.set_title('Histogram of Reviews')\n",
        "plt.savefig('imgs/histogram_reviews.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGDgud9rHd5z"
      },
      "outputs": [],
      "source": [
        "# this is too big, basically useless as they are all binary\n",
        "# sns.pairplot(df[categorical_columns])\n",
        "# plt.savefig('imgs/pairplot_categorical_cols.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob9Z63SxHsYC"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df[numerical_columns])\n",
        "plt.suptitle('Pair Plot Numerical Columns Reviews Dataframe', y = 1.05)\n",
        "plt.savefig('imgs/pairplot_numerical_columns.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJDvsYUgvr5X"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df[numerical_columns + ['score_x']], hue = 'score_x')\n",
        "plt.suptitle('Review rating Pair Plot Numerical Columns Reviews Dataframe', y = 1.05)\n",
        "plt.savefig('imgs/hued_pairplot_numerical_columns.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1HjuI6QIUnZ"
      },
      "outputs": [],
      "source": [
        "for col in numerical_columns:\n",
        "  sns.displot(kind='kde', data=df[col])\n",
        "  plt.title('Density Plot Numerical Columns Reviews Dataframe')\n",
        "  plt.savefig('imgs/density_plot_' + col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtypihEuLnMd"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"google_play\", y='score_x', data=df)\n",
        "plt.title('Box Plot Store vs Rating Reviews Dataframe')\n",
        "\n",
        "plt.savefig('imgs/boxplot_google_play_vs_score_x.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ikHheF_1uzJ"
      },
      "outputs": [],
      "source": [
        "ax = sns.boxplot(x=\"google_play\", y='score_x', data=df)\n",
        "ax = sns.stripplot(x=\"google_play\", y=\"score_x\", data=df, jitter=True, edgecolor=\"gray\")\n",
        "ax.set_title('Box Strip Plot Store vs Rating Reviews Dataframe')\n",
        "\n",
        "plt.savefig('imgs/boxplot_stripped_google_play_vs_score_x.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPD2rflAwAt1"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(x=\"google_play\", y='score_x', data=df)\n",
        "plt.title('Violin Plot Store vs Rating Reviews Dataframe')\n",
        "plt.savefig('imgs/violinplot_google_play_vs_score_x.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w0TUuJMQ7mD"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"score_x\", y='score_y', data=df)\n",
        "plt.title('Box Plot Rating vs Avg. Rating Reviews Dataframe')\n",
        "\n",
        "plt.savefig('imgs/boxplot_score_x_vs_score_y.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaUQfQyW1zKU"
      },
      "outputs": [],
      "source": [
        "ax = sns.boxplot(x=\"score_x\", y='score_y', data=df)\n",
        "ax.set_title('Box Strip Plot Rating vs Avg. Rating Reviews Dataframe')\n",
        "ax = sns.stripplot(x=\"score_x\", y=\"score_y\", data=df, jitter=True, edgecolor=\"gray\")\n",
        "plt.savefig('imgs/boxplot_stripped_score_x_vs_score_y.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCyMZSn-wBdO"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(x=\"score_x\", y='score_y', data=df)\n",
        "plt.title('Violin Plot Rating vs Avg. Rating Reviews Dataframe')\n",
        "\n",
        "plt.savefig('imgs/violinplot_score_x_vs_score_y.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JiKGHViQ9oQ"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df[numerical_columns].corr())\n",
        "plt.title('Correlation Matrix Numerical Columns Reviews Dataframe')\n",
        "plt.savefig('imgs/correlation_matrix_numerical_columns.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yomWfiF_x1XC"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr())\n",
        "plt.title('Correlation Matrix Reviews Dataframe')\n",
        "plt.savefig('imgs/correlation_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skcnMEwj3aYM"
      },
      "outputs": [],
      "source": [
        "pd.plotting.andrews_curves(df.drop(timestamp_columns + text_columns, axis=1), \"score_x\")\n",
        "plt.title('Andrews Curves of single Review')\n",
        "plt.savefig('imgs/andrews_review.png')\n",
        "pd.plotting.parallel_coordinates(df.drop(timestamp_columns + text_columns, axis=1), \"score_x\")\n",
        "plt.title('Parallel Coordinates of single Review')\n",
        "\n",
        "plt.savefig('imgs/parallel_coordinates_review.png')\n",
        "\n",
        "pd.plotting.radviz(df.drop(timestamp_columns + text_columns, axis=1), \"score_x\")\n",
        "plt.title('Radial Visualization of single Review')\n",
        "\n",
        "plt.savefig('imgs/radvix_review.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTPNd8lhBtAV"
      },
      "outputs": [],
      "source": [
        "pd.plotting.andrews_curves(df[numerical_columns + ['score_x']], \"score_x\")\n",
        "plt.title('Numerical Columns Andrews Curves of single Review')\n",
        "plt.savefig('imgs/numerical_andrews_review.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.parallel_coordinates(df[numerical_columns + ['score_x']], \"score_x\")\n",
        "plt.title('Numerical Columns Parallel Coordinates of single Review')\n",
        "\n",
        "plt.savefig('imgs/numerical_parallel_coordinates_review.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "FvydBy05_1e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.plotting.radviz(df[numerical_columns + ['score_x']], \"score_x\")\n",
        "plt.title('Numerical Columns Radial Visualization of single Review')\n",
        "\n",
        "plt.savefig('imgs/numerical_radviz_review.png')\n"
      ],
      "metadata": {
        "id": "UuHd6ZjC_2_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpOXeSSwrH06"
      },
      "source": [
        "# STATISTICAL ANALYIS\n",
        "## DATASET MANIPULATION\n",
        "we try to perform some starting analysis with apps without review text. This means that we can basically incorporate one row for each app and use a dataset which has as number of rows the number of apps we considered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-LN9j23ra0m"
      },
      "outputs": [],
      "source": [
        "# copy over the loaded dataframe\n",
        "df_apps = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-aXH34BrdDR"
      },
      "outputs": [],
      "source": [
        "# drop review specific features\n",
        "df_apps.drop(['replycontent',\n",
        "              'time',\n",
        "              'content',\n",
        "              'score_x',\n",
        "              'username'],\n",
        "             axis = 1,\n",
        "             inplace = True)\n",
        "# now each app has multiple duplicate rows\n",
        "old_length = df_apps.shape[0]\n",
        "df_apps.drop_duplicates(inplace = True)\n",
        "new_length = df_apps.shape[0]\n",
        "print('The reviews dataframe has {} rows while the apps dataframe has {} rows'.format(old_length,new_length))\n",
        "# reset index since now IDs of reviews are not useful anymore\n",
        "df_apps.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5SE6zx7IEfv"
      },
      "source": [
        "we decide to add a feature which is the logarithm of the number of ratings times score. The justification for the log is that we want the distribution to\n",
        "be more concentrated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5oQNkbQIEPJ"
      },
      "outputs": [],
      "source": [
        "df_apps['score_y_times_log_ratings'] = df_apps.score_y * np.log(df_apps.ratings)\n",
        "apps_numerical_columns = numerical_columns\n",
        "apps_numerical_columns.append('score_y_times_log_ratings')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_apps['score_y'].plot(kind = 'density')\n",
        "plt.title('Density Plot score_y Apps Dataset')\n",
        "plt.savefig('imgs/apps_density_plot_score_y.png')"
      ],
      "metadata": {
        "id": "c9yXqnpHM5Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_apps['score_y'].plot(kind = 'hist')\n",
        "plt.title('Hisogram score_y Apps Dataset')\n",
        "plt.savefig('imgs/apps_histogram_score_y.png')"
      ],
      "metadata": {
        "id": "r9JqrGC4Pc7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_apps['ratings'].plot(kind = 'density')\n",
        "plt.title('Density Plot ratings Apps Dataset')\n",
        "plt.savefig('imgs/apps_density_plot_ratings.png')"
      ],
      "metadata": {
        "id": "AEfQBx8ZPMs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the density is now well behaved\n",
        "df_apps['score_y_times_log_ratings'].plot(kind = 'density')\n",
        "plt.title('Density Plot score_y_times_log_ratings Apps Dataset')\n",
        "plt.savefig('imgs/apps_density_plot_score_y_times_log_ratings.png')"
      ],
      "metadata": {
        "id": "QXqTijHgMv--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try with rating categories\n",
        "# we might need to take a subsample of the big size categories\n",
        "# the quantiles are purposely unbalanced to give more precision to high rating reviews\n",
        "df_apps['score_level'] = pd.qcut(x=df_apps['score_y_times_log_ratings'], q = [0, 0.44,0.77, 1.0],\n",
        "                     labels=['Low', 'Mid', 'High'])\n",
        "df_apps['score_level'].hist()\n",
        "plt.title('Histogram score_level Apps Dataset')\n",
        "plt.savefig('imgs/apps_histogram_score_level.png')"
      ],
      "metadata": {
        "id": "iYtB7MUh2Gh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STATISTICAL MODELS FITTING"
      ],
      "metadata": {
        "id": "CMxmbRSyTay8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eKrEEfC08D49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CisSOlw2lGch"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOnXZflylG6U"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A826ISdrlQ0h"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "up = files.upload()\n",
        "import io\n",
        "df  = pd.read_csv(io.BytesIO(up['df_combined_20000.csv']))\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANALYSIS ON SCORE OF THE SINGLE REVIEW (from 1 to 5 stars)\n"
      ],
      "metadata": {
        "id": "Mo3Jz-JoXIg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats"
      ],
      "metadata": {
        "id": "lnCuoeBUNmGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LINEAR REGRESSION - Google**"
      ],
      "metadata": {
        "id": "BwLMtU5hTQbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['score_x']  #linear regression\n",
        "X = df.drop(['score_x', 'app_name_x','ratings','score_y', 'app_name1'], axis=1)"
      ],
      "metadata": {
        "id": "tl9tigG9XW_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)"
      ],
      "metadata": {
        "id": "w4ltr9QWRXDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "b8PAE1cdRbw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "ItjJL0I3Njag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only on Google reviews"
      ],
      "metadata": {
        "id": "zIFD8e6EXjNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df[df['google_play']==1]\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "uA882zSiTmRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df1['score_x']\n",
        "X = df1.drop(['google_play','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "weFrEO49T7LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "cIBAa5IDRisX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate p-values"
      ],
      "metadata": {
        "id": "1hkdxH29Tb9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "hOb5cT83VvLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LINEAR REGRESSION - Apple**"
      ],
      "metadata": {
        "id": "tLoiHdcNTmAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df[df['google_play']==0] #only on Apple reviews\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "f0GNEeWUUbVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df2['score_x']\n",
        "X = df2.drop(['google_play','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "jYx4OwmcUgMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "oDHp334xUmZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate p-values"
      ],
      "metadata": {
        "id": "PMl0sg05Tn96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "XBP0bmlsVwN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LINEAR CLASSIFICATION - both Google and Apple**"
      ],
      "metadata": {
        "id": "cYRane-OUWt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['score_x_dummy'] #linear classification\n",
        "X = df.drop(['score_x_dummy', 'score_x', 'app_name_x','ratings','score_y', 'app_name1'], axis=1)"
      ],
      "metadata": {
        "id": "J1LiMRfIYM-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression().fit(X,Y)\n",
        "#classification coef\n",
        "pd.DataFrame(zip(X.columns, logreg.coef_[0]))"
      ],
      "metadata": {
        "id": "YPnzK26gYTGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "GQWGBlwnVxna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION - only Google**\n",
        "the y is now a dummy with 1 being 4 or 5 stars (the best) and 0 from 1 to 3"
      ],
      "metadata": {
        "id": "MeY84yPpVpIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['score_x_dummy'] = df1['score_x'].apply(lambda x: 1 if x > 3 else 0) #only Google\n",
        "Y = df1['score_x_dummy']\n",
        "X = df1.drop(['score_x_dummy', 'score_x', 'app_name_x','ratings','score_y', 'app_name1', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "lOn-yKOGYVD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression().fit(X,Y)\n",
        "#classification coef\n",
        "pd.DataFrame(zip(X.columns, logreg.coef_[0]))"
      ],
      "metadata": {
        "id": "E8Up-0xFYkwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "81WQe_BmVy7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION - only Apple**"
      ],
      "metadata": {
        "id": "sSC0LgV4V4O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2['score_x_dummy'] = df2['score_x'].apply(lambda x: 1 if x > 3 else 0) #only Apple\n",
        "Y = df2['score_x_dummy']\n",
        "X = df2.drop(['score_x_dummy', 'score_x', 'app_name_x','ratings','score_y', 'app_name1', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "xMivlXm9YpE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression().fit(X,Y)\n",
        "#classification coef\n",
        "pd.DataFrame(zip(X.columns, logreg.coef_[0]))"
      ],
      "metadata": {
        "id": "xpe23uWjYxNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "uEF4yQ4kV0af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ORDERED LOGIT - Google**"
      ],
      "metadata": {
        "id": "u6ZgipNKVEUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "GEg13oPXZMIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ordered_score'] = pd.cut(df['score_x'], bins=5, labels=[1, 2, 3, 4, 5], ordered=True) #ordered logit\n",
        "Y = df['ordered_score']\n",
        "X = df.drop(['ordered_score','score_x_dummy','score_x', 'score_x_dummy1', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "7XIu05tEZQZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_log = OrderedModel(Y,X,\n",
        "                        distr='logit')\n",
        "\n",
        "res_log = mod_log.fit(method='bfgs', disp=False)\n",
        "res_log.summary()"
      ],
      "metadata": {
        "id": "bkNE4fX3Zn30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "y6yJw91FV2dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['ordered_score'] = pd.cut(df1['score_x'], bins=5, labels=[1, 2, 3, 4, 5], ordered=True) #only Google\n",
        "Y = df1['ordered_score']\n",
        "X = df1.drop(['ordered_score','score_x_dummy','score_x', 'score_x_dummy1', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "h3YzmcehZrlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_log = OrderedModel(Y,X,\n",
        "                        distr='logit')\n",
        "\n",
        "res_log = mod_log.fit(method='bfgs', disp=False)\n",
        "res_log.summary()"
      ],
      "metadata": {
        "id": "7lBBTdRmZuj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "g-1oJLaAV3YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ORDERED LOGIT - Apple**"
      ],
      "metadata": {
        "id": "jX1A5KAwWDu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2['ordered_score'] = pd.cut(df2['score_x'], bins=5, labels=[1, 2, 3, 4, 5], ordered=True) #only Apple\n",
        "Y = df2['ordered_score']\n",
        "X = df2.drop(['ordered_score','score_x_dummy','score_x', 'score_x_dummy1', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "GV-gkXqIZ9Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_log = OrderedModel(Y,X,\n",
        "                        distr='logit')\n",
        "\n",
        "res_log = mod_log.fit(method='bfgs', disp=False)\n",
        "res_log.summary()"
      ],
      "metadata": {
        "id": "nnvrmODkZ_WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "6BszQwVfV4Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpbKWo0CaD_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANALYSIS OF FEATURES' EFFECT ON OVERALL APPLICATION SCORE (from 1 to 5 stars)\n"
      ],
      "metadata": {
        "id": "a2TbdmE2WMD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGRESSION**"
      ],
      "metadata": {
        "id": "Aj02y34eWPqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_d['score_x']  #regression\n",
        "X = df_d.drop(['score_x', 'price', 'Unnamed: 0', 'replyContent', 'ratings', 'score_y', \"score_y\", \"at\", \"userName\", \"app_name\",\"content\", 'google_play', 'score_x_dummy1', 'ordered_score'], axis=1)"
      ],
      "metadata": {
        "id": "AQrOyl9BVLL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)"
      ],
      "metadata": {
        "id": "TT8jWk4cVouW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "6EWW0tM5VqL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "bMyYvGS4V5fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSIFICATION**"
      ],
      "metadata": {
        "id": "MFA1rxWVWTTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['score_x_dummy'] = df['score_x'].apply(lambda x: 1 if x > 3 else 0) #classification\n",
        "Y = df['score_x_dummy']\n",
        "X = df.drop(['score_x', 'price', 'Unnamed: 0', 'replyContent', 'ratings', 'score_y', \"score_y\", \"at\", \"userName\", \"app_name\",\"content\"], axis=1)"
      ],
      "metadata": {
        "id": "e73A_F6UW5Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "UfzOnMyaV6rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "YAQ-LVSnWq5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ORDERED LOGIT**"
      ],
      "metadata": {
        "id": "WlyxwZ58WWFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_d['ordered_score'] = pd.cut(df_d['score_x'], bins=5, labels=[1, 2, 3, 4, 5], ordered=True) #ordered logit\n",
        "Y = df_d['ordered_score']\n",
        "X = df_d.drop(['ordered_score','score_x_dummy1', 'google_play', 'score_x', 'price', 'Unnamed: 0', 'replyContent', 'ratings', 'score_y', \"score_y\", \"at\", \"userName\", \"app_name\",\"content\"], axis=1)\n"
      ],
      "metadata": {
        "id": "iN1gAti9Wtk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod_log = OrderedModel(Y,X,\n",
        "                        distr='logit')\n",
        "\n",
        "res_log = mod_log.fit(method='bfgs', disp=False)\n",
        "res_log.summary()"
      ],
      "metadata": {
        "id": "8hhmgJBSWvHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "7rWL1bebV7ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZG-NTdxVaQka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANALYSIS ON SCORE OF THE APP multiplied per NUMBER OF RATINGS\n",
        "This variable can be considered as proxy of success since it take into account both popularity and high quality"
      ],
      "metadata": {
        "id": "4RiFV5txasEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df3['score*ratings']\n",
        "X = df3.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "d4Z60XzWayQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGRESSION**"
      ],
      "metadata": {
        "id": "6PYKjZDYXA5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "945VGccVa4Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "SgXcC1v4V84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGRESSION - only Google**"
      ],
      "metadata": {
        "id": "nWMoXHa2XDzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df3[df['google_play']==1]  #only Google\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "M2O6VQdja6wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df4['score*ratings']\n",
        "X = df4.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "WtVD-PPAa_2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "9lh9aw__bAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "-5uVlIpSV9xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGRESSION - only Apple**"
      ],
      "metadata": {
        "id": "rGXsXjb4XK6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5=df3[df['google_play']==0] #only Apple\n",
        "df5.head()"
      ],
      "metadata": {
        "id": "Mz8va5zVbPKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df5['score*ratings']\n",
        "X = df5.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "Wsk0J61ZbRFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "ChHRBci7bhcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate p-values\n",
        "params = np.append(reg.intercept_,reg.coef_)\n",
        "predictions = reg.predict(X)\n",
        "new_X = np.append(np.ones((len(X),1)), X, axis=1)\n",
        "M_S_E = (sum((Y-predictions)**2))/(len(new_X)-len(new_X[0]))\n",
        "v_b = M_S_E*(np.linalg.inv(np.dot(new_X.T,new_X)).diagonal())\n",
        "s_b = np.sqrt(v_b)\n",
        "t_b = params/ s_b\n",
        "p_val =[2*(1-stats.t.cdf(np.abs(i),(len(new_X)-len(new_X[0])))) for i in t_b]\n",
        "p_val = np.round(p_val,3)\n",
        "p_val"
      ],
      "metadata": {
        "id": "GUa74jhSV-rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANALYSIS ON NUMBER OF REVIEWS AND ANALYSIS OF SCORE OF THE APP\n",
        "I try to understand whether the previous results are driven by one of the two factor of the multiplication"
      ],
      "metadata": {
        "id": "_PXBdHf4b4j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['ratings']\n",
        "X = df.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "U2Sz_diNbmzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['score_y']\n",
        "X = df.drop(['score*ratings','ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size'], axis=1)"
      ],
      "metadata": {
        "id": "cxEORsALb1x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "Op6OierHcC15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df[df['google_play']==1]  #only Google\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "jZCrp_aUcBYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df1['ratings']\n",
        "X = df1.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "jQ1mdiDncrjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "3A94ThaucJSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df1['score_y']\n",
        "X = df1.drop(['score*ratings','ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play'], axis=1)"
      ],
      "metadata": {
        "id": "yuRoTeHecoBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "lmPe7f4DcxFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXPTPDkFcy5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df[df['google_play']==0] #only Apple"
      ],
      "metadata": {
        "id": "ixvWuwTpczDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df2['ratings']\n",
        "X = df2.drop(['score*ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play', 'log_ratings', 'score*log(ratings)'], axis=1)"
      ],
      "metadata": {
        "id": "A6gQKDyfzWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "gv3k1zpbzWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df2['score_y']\n",
        "X = df2.drop(['score*ratings','ratings','score_x_dummy','score_x', 'app_name_x','ratings','score_y', 'app_name1', 'size', 'google_play', 'log_ratings', 'score*log(ratings)'], axis=1)"
      ],
      "metadata": {
        "id": "rMKui44SzWBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X,Y)\n",
        "#reg.coef_\n",
        "pd.DataFrame(zip(X.columns, reg.coef_))"
      ],
      "metadata": {
        "id": "Ym_xiLd5zWBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FREQUENT MONOGRAM ANALYSIS"
      ],
      "metadata": {
        "id": "iof-rEgwj0nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(background_color=\"white\", max_words=250, colormap=\"Set2\")\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "stop = stop + ['app', 'APP' ,'ap', 'App', 'apps', 'application', 'browser', 'website', 'websites', 'chrome', 'click', 'web', 'ip', 'address',\n",
        "            'files', 'android', 'browse', 'service', 'use', 'one', 'download', 'email', 'Launcher', 'video', 'Video', 'photo', 'Photo','edit', 'editing', 'video', 'good']"
      ],
      "metadata": {
        "id": "0v-N5-FVjzsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4_z734bvA5C"
      },
      "outputs": [],
      "source": [
        "## Wordcloud Function\n",
        "def wc(data,bgcolor,title):\n",
        "    plt.figure(figsize = (100,100))\n",
        "    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50, )\n",
        "    wc.generate(' '.join(data))\n",
        "    plt.imshow(wc)\n",
        "    plt.axis('off')\n",
        "    plt.title('Common Words in Reviews')\n",
        "\n",
        "## Frequency of words in translated review column\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "#from stop_words import get_stop_words\n",
        "import re\n",
        "\n",
        "top_N = 100\n",
        "\n",
        "pos_review_lower = df_reviews[df_reviews['score']>=4]['content'].str.lower().str.cat(sep=' ')\n",
        "neg_review_lower = df_reviews[df_reviews['score']<3]['content'].str.lower().str.cat(sep=' ')\n",
        "neu_review_lower = df_reviews[df_reviews['score']==3]['content'].str.lower().str.cat(sep=' ')\n",
        "\n",
        "\n",
        "## Remove Punctuations\n",
        "pos_review_remove_pun = re.sub('[^A-Za-z]+', ' ', pos_review_lower)\n",
        "neg_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neg_review_lower)\n",
        "neu_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neu_review_lower)\n",
        "\n",
        "#remove all the stopwords from the text\n",
        "pos_word_tokens_tags = word_tokenize(pos_review_remove_pun)\n",
        "neg_word_tokens_tags = word_tokenize(neg_review_remove_pun)\n",
        "neu_word_tokens_tags = word_tokenize(neu_review_remove_pun)\n",
        "pos_filtered_sentence_tags = [w_tags for w_tags in pos_word_tokens_tags if not w_tags in stop]\n",
        "pos_filtered_sentence_tags = []\n",
        "for w_tags in pos_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        pos_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neg_filtered_sentence_tags = [w_tags for w_tags in neg_word_tokens_tags if not w_tags in stop]\n",
        "neg_filtered_sentence_tags = []\n",
        "for w_tags in neg_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neg_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neu_filtered_sentence_tags = [w_tags for w_tags in neu_word_tokens_tags if not w_tags in stop]\n",
        "neu_filtered_sentence_tags = []\n",
        "for w_tags in neu_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neu_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "# Remove characters which have length less than 2\n",
        "\n",
        "pos_without_single_chr_rev = [word_tags for word_tags in pos_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neg_without_single_chr_rev = [word_tags for word_tags in neg_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neu_without_single_chr_rev = [word_tags for word_tags in neu_filtered_sentence_tags if len(word_tags) > 2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image of negative words\n",
        "wc(neg_without_single_chr_rev,'white','Common Words' )"
      ],
      "metadata": {
        "id": "prQnK6j0kMXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image of positive words\n",
        "wc(pos_without_single_chr_rev,'white','Common Words' )"
      ],
      "metadata": {
        "id": "Sdbr8zC1kStO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FREQUENT BIGRAM\n",
        "I try to understand whether there is a relation between good (or bad) reviews and some frequent bigram (group of two words)"
      ],
      "metadata": {
        "id": "p8Z6_qA2nswG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove NaN\n",
        "dataset[\"content\"]= dataset[\"content\"].fillna(\"\")"
      ],
      "metadata": {
        "id": "SDu6F8nAnrsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rng3uw2oC9v2"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(background_color=\"white\", max_words=250, colormap=\"Set2\")\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "from collections import Counter\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "stop = stop + ['app', 'APP' ,'ap', 'App', 'apps', 'application', 'browser', 'website', 'websites', 'chrome', 'click', 'web', 'ip', 'address',\n",
        "            'files', 'android', 'browse', 'service', 'use', 'one', 'download', 'email', 'Launcher','please','love','it','the','i',\n",
        "              'I','my','like','really','every','would','even','though','game','review']\n",
        "\n",
        "\n",
        "def wc(data,bgcolor,title):\n",
        "    plt.figure(figsize = (100,100))\n",
        "    wc = WordCloud(background_color = bgcolor, max_words = 300,  max_font_size = 50, )\n",
        "    wc.generate(' '.join(data))\n",
        "    plt.imshow(wc)\n",
        "    plt.axis('off')\n",
        "    plt.title('Common Phrases in Reviews')\n",
        "\n",
        "\n",
        "\n",
        "def pair_split(x):\n",
        "    words = re.sub('[^A-Za-z_]+', ' ', x)\n",
        "    words = words.split()\n",
        "    words_new = [x for x in words if x not in stop]\n",
        "    if len(words_new) == 1:\n",
        "        return words_new\n",
        "    else:\n",
        "        pairs = [words_new[i]+'_'+words_new[i+1] for i in range(len(words_new)-1)]\n",
        "        return pairs\n",
        "\n",
        "\n",
        "\n",
        "## Frequency of words in translated review column\n",
        "\n",
        "top_N = 100\n",
        "\n",
        "## Get every pair of words from the reviews\n",
        "\n",
        "pos_review_lower = g_df[g_df['score']>=4]['content'].str.lower().apply(pair_split).apply(lambda x: \" \".join(x)).str.cat(sep=' ')\n",
        "neg_review_lower = g_df[g_df['score']<3]['content'].str.lower().apply(pair_split).apply(lambda x: \" \".join(x)).str.cat(sep=' ')\n",
        "neu_review_lower = g_df[g_df['score']==3]['content'].str.lower().apply(pair_split).apply(lambda x: \" \".join(x)).str.cat(sep=' ')\n",
        "\n",
        "\n",
        "pos_review_lower_rem = pos_review_lower.split(' ')\n",
        "pos_review_lower_rem = [a for a  in pos_review_lower_rem if a.find('_') >0]\n",
        "pos_review_remove_pun = \" \".join(pos_review_lower_rem)\n",
        "\n",
        "neg_review_lower_rem = neg_review_lower.split(' ')\n",
        "neg_review_lower_rem = [a for a  in neg_review_lower_rem if a.find('_') >0]\n",
        "neg_review_remove_pun = \" \".join(neg_review_lower_rem)\n",
        "\n",
        "neu_review_lower_rem = neu_review_lower.split(' ')\n",
        "neu_review_lower_rem = [a for a  in neu_review_lower_rem if a.find('_') >0]\n",
        "neu_review_remove_pun = \" \".join(neu_review_lower_rem)\n",
        "\n",
        "\n",
        "pos_word_tokens_tags = word_tokenize(pos_review_remove_pun)\n",
        "neg_word_tokens_tags = word_tokenize(neg_review_remove_pun)\n",
        "neu_word_tokens_tags = word_tokenize(neu_review_remove_pun)\n",
        "pos_filtered_sentence_tags = [w_tags for w_tags in pos_word_tokens_tags if not w_tags in stop]\n",
        "pos_filtered_sentence_tags = []\n",
        "for w_tags in pos_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        pos_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neg_filtered_sentence_tags = [w_tags for w_tags in neg_word_tokens_tags if not w_tags in stop]\n",
        "neg_filtered_sentence_tags = []\n",
        "for w_tags in neg_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neg_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "neu_filtered_sentence_tags = [w_tags for w_tags in neu_word_tokens_tags if not w_tags in stop]\n",
        "neu_filtered_sentence_tags = []\n",
        "for w_tags in neu_word_tokens_tags:\n",
        "    if w_tags not in stop:\n",
        "        neu_filtered_sentence_tags.append(w_tags)\n",
        "\n",
        "# Remove characters which have length less than 2\n",
        "\n",
        "pos_without_single_chr_rev = [word_tags for word_tags in pos_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neg_without_single_chr_rev = [word_tags for word_tags in neg_filtered_sentence_tags if len(word_tags) > 2]\n",
        "neu_without_single_chr_rev = [word_tags for word_tags in neu_filtered_sentence_tags if len(word_tags) > 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count negative\n",
        "from collections import Counter\n",
        "counts = Counter(neg_without_single_chr_rev)\n",
        "count_top50 = counts.most_common(50)\n",
        "count_top50"
      ],
      "metadata": {
        "id": "bQqfOXwIrdKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph frequency negative\n",
        "import seaborn as sns\n",
        "count_top30_df = pd.DataFrame(count_top30, columns=[\"Phrases\",\"Count\"])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1)\n",
        "category_plot = sns.barplot(x=\"Phrases\",y =\"Count\",data=count_top30_df, palette = \"RdYlBu\")\n",
        "category_plot.set_xticklabels(category_plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "plt.title('Common Phrases in Negative Reviews',size = 18)"
      ],
      "metadata": {
        "id": "CGJj09dRrgdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #count positive\n",
        "from collections import Counter\n",
        "counts = Counter(pos_without_single_chr_rev)\n",
        "count_top30 = counts.most_common(50)\n",
        "count_top30"
      ],
      "metadata": {
        "id": "3kh13120rg97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph positive\n",
        "count_top30_df = pd.DataFrame(count_top30, columns=[\"Phrases\",\"Count\"])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1)\n",
        "category_plot = sns.barplot(x=\"Phrases\",y =\"Count\",data=count_top30_df, palette = \"YlGnBu_r\")\n",
        "category_plot.set_xticklabels(category_plot.get_xticklabels(), rotation=90, ha=\"right\")\n",
        "plt.title('Common Phrases in Positive Reviews',size = 18)"
      ],
      "metadata": {
        "id": "IVtglD5zripd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}